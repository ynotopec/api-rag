# Core
#OPENAI_API_BASE=http://localhost:8000/v1
#OPENAI_API_KEY=your-key
#UPSTREAM_MODEL_RAG=ai-chat
MODEL_RAG=ai-rag

# Vectorstore
VECTORSTORE_DIR=vectorstore_db
#WIKI_TXT=wiki.txt
RAG_TOP_K=8
RAG_FORCE_REBUILD=true
#false

# Strategy
RAG_QUERY_STRATEGY=rewrite+hyde  # simple, rewrite, hyde, rewrite+hyde
RAG_HISTORY_WINDOW=6

# Optimizations (all default to true except query classification)
ENABLE_HYBRID_SEARCH=true
ENABLE_RERANKING=true
ENABLE_SEMANTIC_DEDUP=true
ENABLE_CACHING=true
ENABLE_QUERY_CLASSIFICATION=false

# Chunking
CHUNKING_STRATEGY=recursive  # recursive, semantic, hierarchical
CHUNK_SIZE=800
CHUNK_OVERLAP=100

# Models
EMBEDDING_MODEL=BAAI/bge-m3
RERANKER_MODEL=BAAI/bge-reranker-v2-m3
#cross-encoder/ms-marco-MiniLM-L-6-v2

# Performance
MAX_WORKERS=4
CACHE_MAX_SIZE=1000

